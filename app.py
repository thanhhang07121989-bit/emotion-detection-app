
import streamlit as st
import numpy as np
import pandas as pd
import pickle
import re
from tensorflow import keras
from tensorflow.keras.preprocessing.sequence import pad_sequences
import warnings
warnings.filterwarnings('ignore')

import gdown
import tempfile

# Download model t·ª´ Google Drive
model_file = 'model_cnn.h5'
if not os.path.exists(model_file):
    try:
        st.warning("üì• ƒêang t·∫£i model t·ª´ Google Drive (l·∫ßn ƒë·∫ßu ~3-5 ph√∫t)...")
        file_id = '1vjCqFWmWEQeVEofVJvn-J6eNhE4GdiEI'
        url = f'https://drive.google.com/uc?id={file_id}'
        gdown.download(url, model_file, quiet=False)
        st.success("‚úÖ T·∫£i model xong!")
    except Exception as e:
        st.error(f"‚ùå L·ªói t·∫£i model: {e}")
        st.stop()

st.set_page_config(page_title="Emotion Detection CNN", page_icon="ü§ñ", layout="wide")

st.title("ü§ñ Ph√¢n T√≠ch C·∫£m X√∫c VƒÉn B·∫£n")
st.markdown("**Model:** CNN | **Nh√£n:** 28 c·∫£m x√∫c | **Dataset:** GoEmotions")
st.markdown("---")

# Load model
@st.cache_resource
def load_models():
    try:
        model = keras.models.load_model('model_cnn.h5')
        with open('tokenizer.pkl', 'rb') as f:
            tokenizer = pickle.load(f)
        label_map = pd.read_csv('label_map.csv')
        return model, tokenizer, label_map
    except Exception as e:
        st.error(f"‚ùå L·ªói: {str(e)}")
        return None, None, None

def normalize_text(text):
    if not text:
        return ""
    text = text.lower()
    text = re.sub(r'http\S+|www\S+', '', text)
    text = re.sub(r'@\w+|#\w+', '', text)
    text = ' '.join(text.split())
    return text

with st.spinner("‚è≥ ƒêang t·∫£i CNN..."):
    model, tokenizer, label_map = load_models()

if model is None:
    st.stop()

st.success("‚úÖ Model s·∫µn s√†ng!")

col1, col2 = st.columns([1.2, 1], gap="large")

with col1:
    st.subheader("üìù NH·∫¨P VƒÇN B·∫¢N")
    user_text = st.text_area(
        label="Nh·∫≠p c√¢u ti·∫øng Anh",
        placeholder="V√≠ d·ª•: I am so happy and grateful today!",
        height=250,
        label_visibility="collapsed"
    )
    
    st.subheader("‚öôÔ∏è THRESHOLD")
    threshold = st.slider("", 0.0, 1.0, 0.5, 0.05, label_visibility="collapsed")
    st.metric("Threshold hi·ªán t·∫°i", f"{threshold:.2f}")
    
    analyze_button = st.button("üöÄ PH√ÇN T√çCH C·∫¢M X√öC", use_container_width=True)

with col2:
    st.subheader("üòä K·∫æT QU·∫¢")
    
    if analyze_button and user_text:
        cleaned_text = normalize_text(user_text)
        word_count = len(cleaned_text.split())
        
        if word_count < 3:
            st.warning(f"‚ö†Ô∏è Text qu√° ng·∫Øn ({word_count} t·ª´)")
        else:
            with st.spinner("‚è≥ ƒêang ph√¢n t√≠ch..."):
                # Tokenize
                seq = tokenizer.texts_to_sequences([cleaned_text])
                padded = pad_sequences(seq, maxlen=100)
                
                # Predict
                predictions = model.predict(padded, verbose=0)[0]
                
                # Filter
                detected_idx = np.where(predictions > threshold)[0]
                if len(detected_idx) == 0:
                    detected_idx = [np.argmax(predictions)]
                
                emotions = label_map.iloc[detected_idx]['label_name'].tolist()
                
                st.success(f"‚úÖ Ph√°t hi·ªán {len(emotions)} c·∫£m x√∫c")
                for e in emotions[:5]:
                    st.info(f"üòä {e.capitalize()}")

st.markdown("---")

if analyze_button and user_text:
    cleaned_text = normalize_text(user_text)
    if len(cleaned_text.split()) >= 3:
        seq = tokenizer.texts_to_sequences([cleaned_text])
        padded = pad_sequences(seq, maxlen=100)
        predictions = model.predict(padded, verbose=0)[0]
        
        st.subheader("üìä CHI TI·∫æT T·ª™NG NH√ÉN")
        results_df = pd.DataFrame({
            'C·∫£m x√∫c': label_map['label_name'],
            'X√°c su·∫•t (%)': (predictions * 100).round(2)
        }).sort_values('X√°c su·∫•t (%)', ascending=False)
        
        st.dataframe(results_df, use_container_width=True, height=400, hide_index=True)
        st.bar_chart(results_df.head(10).set_index('C·∫£m x√∫c')['X√°c su·∫•t (%)'])


st.markdown("ü§ñ Emotion Detection - CNN Model")
