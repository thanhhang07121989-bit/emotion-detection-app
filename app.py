
import streamlit as st
import numpy as np
import pandas as pd
import pickle
import re
from tensorflow import keras
from tensorflow.keras.preprocessing.sequence import pad_sequences
import warnings
warnings.filterwarnings('ignore')

# === THÃŠM CODE NÃ€Y ===
import gdown

# Download model tá»« Google Drive
if not os.path.exists('model_cnn.h5'):
    st.warning("ğŸ“¥ Äang táº£i model tá»« Google Drive... (láº§n Ä‘áº§u khoáº£ng 3-5 phÃºt)")
    file_id = '1vjCqFWmWEQeVEofVJvn-J6eNhE4GdiEI'  # â† ID cá»§a báº¡n
    url = f'https://drive.google.com/uc?id={file_id}'
    gdown.download(url, 'model_cnn.h5', quiet=False)
    st.success("âœ… Táº£i model xong!")
# === Háº¾T CODE THÃŠM ===

st.set_page_config(page_title="Emotion Detection CNN", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– PhÃ¢n TÃ­ch Cáº£m XÃºc VÄƒn Báº£n")
st.markdown("**Model:** CNN | **NhÃ£n:** 28 cáº£m xÃºc | **Dataset:** GoEmotions")
st.markdown("---")

# Load model
@st.cache_resource
def load_models():
    try:
        model = keras.models.load_model('model_cnn.h5')
        with open('tokenizer.pkl', 'rb') as f:
            tokenizer = pickle.load(f)
        label_map = pd.read_csv('label_map.csv')
        return model, tokenizer, label_map
    except Exception as e:
        st.error(f"âŒ Lá»—i: {str(e)}")
        return None, None, None

def normalize_text(text):
    if not text:
        return ""
    text = text.lower()
    text = re.sub(r'http\S+|www\S+', '', text)
    text = re.sub(r'@\w+|#\w+', '', text)
    text = ' '.join(text.split())
    return text

with st.spinner("â³ Äang táº£i CNN..."):
    model, tokenizer, label_map = load_models()

if model is None:
    st.stop()

st.success("âœ… Model sáºµn sÃ ng!")

col1, col2 = st.columns([1.2, 1], gap="large")

with col1:
    st.subheader("ğŸ“ NHáº¬P VÄ‚N Báº¢N")
    user_text = st.text_area(
        label="Nháº­p cÃ¢u tiáº¿ng Anh",
        placeholder="VÃ­ dá»¥: I am so happy and grateful today!",
        height=250,
        label_visibility="collapsed"
    )
    
    st.subheader("âš™ï¸ THRESHOLD")
    threshold = st.slider("", 0.0, 1.0, 0.5, 0.05, label_visibility="collapsed")
    st.metric("Threshold hiá»‡n táº¡i", f"{threshold:.2f}")
    
    analyze_button = st.button("ğŸš€ PHÃ‚N TÃCH Cáº¢M XÃšC", use_container_width=True)

with col2:
    st.subheader("ğŸ˜Š Káº¾T QUáº¢")
    
    if analyze_button and user_text:
        cleaned_text = normalize_text(user_text)
        word_count = len(cleaned_text.split())
        
        if word_count < 3:
            st.warning(f"âš ï¸ Text quÃ¡ ngáº¯n ({word_count} tá»«)")
        else:
            with st.spinner("â³ Äang phÃ¢n tÃ­ch..."):
                # Tokenize
                seq = tokenizer.texts_to_sequences([cleaned_text])
                padded = pad_sequences(seq, maxlen=100)
                
                # Predict
                predictions = model.predict(padded, verbose=0)[0]
                
                # Filter
                detected_idx = np.where(predictions > threshold)[0]
                if len(detected_idx) == 0:
                    detected_idx = [np.argmax(predictions)]
                
                emotions = label_map.iloc[detected_idx]['label_name'].tolist()
                
                st.success(f"âœ… PhÃ¡t hiá»‡n {len(emotions)} cáº£m xÃºc")
                for e in emotions[:5]:
                    st.info(f"ğŸ˜Š {e.capitalize()}")

st.markdown("---")

if analyze_button and user_text:
    cleaned_text = normalize_text(user_text)
    if len(cleaned_text.split()) >= 3:
        seq = tokenizer.texts_to_sequences([cleaned_text])
        padded = pad_sequences(seq, maxlen=100)
        predictions = model.predict(padded, verbose=0)[0]
        
        st.subheader("ğŸ“Š CHI TIáº¾T Tá»ªNG NHÃƒN")
        results_df = pd.DataFrame({
            'Cáº£m xÃºc': label_map['label_name'],
            'XÃ¡c suáº¥t (%)': (predictions * 100).round(2)
        }).sort_values('XÃ¡c suáº¥t (%)', ascending=False)
        
        st.dataframe(results_df, use_container_width=True, height=400, hide_index=True)
        st.bar_chart(results_df.head(10).set_index('Cáº£m xÃºc')['XÃ¡c suáº¥t (%)'])

st.markdown("ğŸ¤– Emotion Detection - CNN Model")