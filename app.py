import streamlit as st
import numpy as np
import pandas as pd
import pickle
import re
import os
from tensorflow import keras
from tensorflow.keras.preprocessing.sequence import pad_sequences
import warnings
warnings.filterwarnings('ignore')

# === Gá»˜P 2 PHáº¦N MODEL ===
@st.cache_resource
def prepare_model():
    if not os.path.exists('model_cnn.h5'):
        if os.path.exists('model_part1.bin') and os.path.exists('model_part2.bin'):
            with open('model_part1.bin', 'rb') as f:
                data1 = f.read()
            with open('model_part2.bin', 'rb') as f:
                data2 = f.read()
            with open('model_cnn.h5', 'wb') as f:
                f.write(data1 + data2)
    return True

prepare_model()
# === Háº¾T Gá»˜P ===

st.set_page_config(page_title="Emotion Detection CNN", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– PhÃ¢n TÃ­ch Cáº£m XÃºc VÄƒn Báº£n")
st.markdown("**Model:** CNN | **NhÃ£n:** 28 cáº£m xÃºc | **Dataset:** GoEmotions")
st.markdown("---")

# Load model
@st.cache_resource
def load_models():
    try:
        model = keras.models.load_model('model_cnn.h5')

        with open('tokenizer.pkl', 'rb') as f:
            tokenizer = pickle.load(f)

        label_map = pd.read_csv('label_map.csv')

        return model, tokenizer, label_map
    except Exception as e:
        st.error(f"âŒ Lá»—i: {str(e)}")
        return None, None, None

def normalize_text(text):
    if not text:
        return ""
    text = text.lower()
    text = re.sub(r'http\S+|www\S+', '', text)
    text = re.sub(r'@\w+|#\w+', '', text)
    text = " ".join(text.split())
    return text

# Dictionary emoji phÃ¹ há»£p vá»›i cáº£m xÃºc (28 nhÃ£n)
emotion_emoji = {
    "admiration": "ğŸ˜",
    "amusement": "ğŸ˜‚",
    "anger": "ğŸ˜ ",
    "annoyance": "ğŸ˜¤",
    "approval": "ğŸ‘",
    "caring": "ğŸ¤—",
    "confusion": "ğŸ˜•",
    "curiosity": "ğŸ¤”",
    "desire": "â¤ï¸",
    "disappointment": "ğŸ˜",
    "disapproval": "ğŸ‘",
    "disgust": "ğŸ¤®",
    "embarrassment": "ğŸ˜³",
    "excitement": "ğŸ‰",
    "fear": "ğŸ˜¨",
    "gratitude": "ğŸ™",
    "grief": "ğŸ˜­",
    "joy": "ğŸ˜Š",
    "love": "â¤ï¸",
    "nervousness": "ğŸ˜°",
    "optimism": "ğŸŒˆ",
    "pride": "ğŸ†",
    "realization": "ğŸ’¡",
    "relief": "ğŸ˜Œ",
    "remorse": "ğŸ˜”",
    "sadness": "ğŸ˜¢",
    "surprise": "ğŸ˜²",
    "neutral": "ğŸ˜",
}
# Load models
with st.spinner("â³ Äang táº£i CNN..."):
    model, tokenizer, label_map = load_models()

if model is None:
    st.stop()

# ====== VALIDATION ======
n_classes = int(model.output_shape[-1])
n_labels = len(label_map)

if n_labels != n_classes:
    st.error(
        f"âŒ label_map.csv KHÃ”NG KHá»šP model!\n"
        f"- Model output: {n_classes}\n"
        f"- label_map rows: {n_labels}"
    )
    st.stop()

st.success("âœ… Model sáºµn sÃ ng!")

# ====== NEW: SAFE LABEL LOOKUP + NEUTRAL RULE ======
id2label = dict(zip(label_map["label_id"], label_map["label_name"]))
NEUTRAL_ID = 27

# Báº¡n chá»‰nh 2 tham sá»‘ nÃ y Ä‘á»ƒ â€œÄ‘á»¡ saiâ€
UNCERTAIN_CUTOFF_DEFAULT = 0.45  # 0.40/0.45/0.50
TOP_K_DEFAULT = 3

# Giao diá»‡n
col1, col2 = st.columns([1.2, 1], gap="large")

with col1:
    st.subheader("ğŸ“ NHáº¬P VÄ‚N Báº¢N")
    user_text = st.text_area(
        label="Nháº­p cÃ¢u tiáº¿ng Anh",
        placeholder="VÃ­ dá»¥: I am so happy and grateful today!",
        height=250,
        label_visibility="collapsed"
    )

    st.subheader("âš™ï¸ THRESHOLD")
    threshold = st.slider("", 0.0, 1.0, 0.5, 0.05, label_visibility="collapsed")
    st.metric("Threshold hiá»‡n táº¡i", f"{threshold:.2f}")

    # NEW: thÃªm cutoff + top_k Ä‘á»ƒ báº¡n tune nhanh
    st.subheader("ğŸ§° TINH CHá»ˆNH (anti-sai)")
    uncertain_cutoff = st.slider(
        "Uncertain cutoff (max_score < cutoff => Neutral)",
        0.0, 1.0, UNCERTAIN_CUTOFF_DEFAULT, 0.05
    )
    top_k = st.slider("Top-k labels", 1, 10, TOP_K_DEFAULT, 1)

    analyze_button = st.button("ğŸš€ PHÃ‚N TÃCH Cáº¢M XÃšC", use_container_width=True)

with col2:
    st.subheader("ğŸ˜Š Káº¾T QUáº¢")

    if analyze_button and user_text:
        cleaned_text = normalize_text(user_text)
        word_count = len(cleaned_text.split())

        if word_count < 3:
            st.warning(f"âš ï¸ Text quÃ¡ ngáº¯n ({word_count} tá»«)")
        else:
            with st.spinner("â³ Äang phÃ¢n tÃ­ch..."):
                # Tokenize
                seq = tokenizer.texts_to_sequences([cleaned_text])
                padded = pad_sequences(seq, maxlen=250, padding='post', truncating='post')

                # Predict
                pred = model.predict(padded, verbose=0)[0]  # (28,)

                max_score = float(np.max(pred))
                max_idx = int(np.argmax(pred))

                # ===== NEW FILTER LOGIC =====
                if max_score < float(uncertain_cutoff):
                    detected_idx = [NEUTRAL_ID]
                else:
                    detected_idx = np.where(pred >= threshold)[0].tolist()
                    if len(detected_idx) == 0:
                        detected_idx = [max_idx]
                    detected_idx = sorted(detected_idx, key=lambda i: float(pred[i]), reverse=True)[: int(top_k)]

                emotions = [id2label[int(i)] for i in detected_idx]
                scores = [float(pred[int(i)]) for i in detected_idx]

                # Debug nhá» Ä‘á»ƒ báº¡n biáº¿t model Ä‘ang tá»± tin Ä‘áº¿n Ä‘Ã¢u
                st.caption(f"DEBUG: max_score={max_score:.3f} | max_label={id2label[max_idx]} | threshold={threshold:.2f} | cutoff={uncertain_cutoff:.2f}")

                st.success(f"âœ… PhÃ¡t hiá»‡n {len(emotions)} cáº£m xÃºc")
                for e, score in zip(emotions, scores):
                    emotion_name = str(e).lower().strip()
                    emoji = emotion_emoji.get(emotion_name, 'ğŸ˜Š')
                    st.info(f"{emoji} {str(e).capitalize()} ({score*100:.1f}%)")

st.markdown("---")

if analyze_button and user_text:
    cleaned_text = normalize_text(user_text)
    if len(cleaned_text.split()) >= 3:
        try:
            seq = tokenizer.texts_to_sequences([cleaned_text])
            padded = pad_sequences(seq, maxlen=100, padding='post', truncating='post')
            predictions = model.predict(padded, verbose=0)[0]

            st.subheader("ğŸ“Š CHI TIáº¾T Tá»ªNG NHÃƒN")

            emotion_names = label_map['label_name'].values
            scores = (predictions * 100).round(2)

            if len(emotion_names) != len(scores):
                st.error(f"âŒ Mismatch: {len(emotion_names)} labels â‰  {len(scores)} scores")
                st.stop()

            results_df = pd.DataFrame({
                "Cáº£m xÃºc": emotion_names,
                "XÃ¡c suáº¥t (%)": scores
            }).sort_values("XÃ¡c suáº¥t (%)", ascending=False)

            st.dataframe(results_df, use_container_width=True, height=400, hide_index=True)

            try:
                chart_data = results_df.head(10).copy()
                chart_data = chart_data.set_index("Cáº£m xÃºc")
                st.bar_chart(chart_data)
            except Exception as chart_error:
                st.warning(f"âš ï¸ KhÃ´ng thá»ƒ hiá»ƒn thá»‹ biá»ƒu Ä‘á»“: {str(chart_error)}")

        except Exception as e:
            st.error(f"âŒ Lá»—i phÃ¢n tÃ­ch: {str(e)}")

st.markdown("ğŸ¤– Emotion Detection - CNN Model")
