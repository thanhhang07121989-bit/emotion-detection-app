import streamlit as st
import numpy as np
import pandas as pd
import pickle
import re
import os
from tensorflow import keras
from tensorflow.keras.preprocessing.sequence import pad_sequences
import warnings
warnings.filterwarnings('ignore')

# === Gá»˜P 2 PHáº¦N MODEL ===
@st.cache_resource
def prepare_model():
    if not os.path.exists('model_cnn.h5'):
        if os.path.exists('model_part1.bin') and os.path.exists('model_part2.bin'):
            with open('model_part1.bin', 'rb') as f:
                data1 = f.read()
            with open('model_part2.bin', 'rb') as f:
                data2 = f.read()
            with open('model_cnn.h5', 'wb') as f:
                f.write(data1 + data2)
    return True

prepare_model()
# === Háº¾T Gá»˜P ===

st.set_page_config(page_title="Emotion Detection CNN", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– PhÃ¢n TÃ­ch Cáº£m XÃºc VÄƒn Báº£n")
st.markdown("**Model:** CNN | **NhÃ£n:** 28 cáº£m xÃºc | **Dataset:** GoEmotions")
st.markdown("---")

# Load model
@st.cache_resource
def load_models():
    try:
        model = keras.models.load_model('model_cnn.h5')
        
        with open('tokenizer.pkl', 'rb') as f:
            tokenizer = pickle.load(f)
        
        label_map = pd.read_csv('label_map.csv')
        
        return model, tokenizer, label_map
    except Exception as e:
        st.error(f"âŒ Lá»—i: {str(e)}")
        return None, None, None

def normalize_text(text):
    if not text:
        return ""
    text = text.lower()
    text = re.sub(r'http\S+|www\S+', '', text)
    text = re.sub(r'@\w+|#\w+', '', text)
    text = " ".join(text.split())
    return text

# Dictionary emoji phÃ¹ há»£p vá»›i cáº£m xÃºc (28 nhÃ£n)
emotion_emoji = {
    'admiration': 'ğŸ˜',
    'amusement': 'ğŸ˜‚',
    'anger': 'ğŸ˜ ',
    'annoyance': 'ğŸ˜¤',
    'approval': 'ğŸ‘',
    'caring': 'ğŸ¤—',
    'confusion': 'ğŸ˜•',
    'curiosity': 'ğŸ¤”',
    'desire': 'â¤ï¸',
    'disappointment': 'ğŸ˜',
    'disapproval': 'ğŸ‘',
    'disgust': 'ğŸ¤®',
    'embarrassment': 'ğŸ˜³',
    'excitement': 'ğŸ‰',
    'fear': 'ğŸ˜¨',
    'gratitude': 'ğŸ™',
    'grief': 'ğŸ˜­',
    'hope': 'ğŸŒŸ',
    'horror': 'ğŸ˜±',
    'joy': 'ğŸ˜Š',
    'love': 'â¤ï¸',
    'neutral': 'ğŸ˜',
    'nostalgia': 'ğŸŒ…',
    'optimism': 'ğŸŒˆ',
    'pride': 'ğŸ†',
    'realization': 'ğŸ’¡',
    'relief': 'ğŸ˜Œ',
    'remorse': 'ğŸ˜”',
}

# Load models
with st.spinner("â³ Äang táº£i CNN..."):
    model, tokenizer, label_map = load_models()

if model is None:
    st.stop()

# ====== VALIDATION ======
n_classes = int(model.output_shape[-1])
n_labels = len(label_map)

if n_labels != n_classes:
    st.error(
        f"âŒ label_map.csv KHÃ”NG KHá»šP model!\n"
        f"- Model output: {n_classes}\n"
        f"- label_map rows: {n_labels}"
    )
    st.stop()

st.success("âœ… Model sáºµn sÃ ng!")

# Giao diá»‡n
col1, col2 = st.columns([1.2, 1], gap="large")

with col1:
    st.subheader("ğŸ“ NHáº¬P VÄ‚N Báº¢N")
    user_text = st.text_area(
        label="Nháº­p cÃ¢u tiáº¿ng Anh",
        placeholder="VÃ­ dá»¥: I am so happy and grateful today!",
        height=250,
        label_visibility="collapsed"
    )
    
    st.subheader("âš™ï¸ THRESHOLD")
    threshold = st.slider("", 0.0, 1.0, 0.5, 0.05, label_visibility="collapsed")
    st.metric("Threshold hiá»‡n táº¡i", f"{threshold:.2f}")
    
    analyze_button = st.button("ğŸš€ PHÃ‚N TÃCH Cáº¢M XÃšC", use_container_width=True)

with col2:
    st.subheader("ğŸ˜Š Káº¾T QUáº¢")
    
    if analyze_button and user_text:
        cleaned_text = normalize_text(user_text)
        word_count = len(cleaned_text.split())
        
        if word_count < 3:
            st.warning(f"âš ï¸ Text quÃ¡ ngáº¯n ({word_count} tá»«)")
        else:
            with st.spinner("â³ Äang phÃ¢n tÃ­ch..."):
                # Tokenize
                seq = tokenizer.texts_to_sequences([cleaned_text])
                # FIX: ThÃªm padding='post', truncating='post'
                padded = pad_sequences(seq, maxlen=100, padding='post', truncating='post')
                
                # Predict
                predictions = model.predict(padded, verbose=0)[0]
                
                # Filter
                detected_idx = np.where(predictions > threshold)[0]
                if len(detected_idx) == 0:
                    detected_idx = [np.argmax(predictions)]
                
                emotions = label_map.iloc[detected_idx]['label_name'].tolist()
                scores = predictions[detected_idx]
                
                st.success(f"âœ… PhÃ¡t hiá»‡n {len(emotions)} cáº£m xÃºc")
                for e, score in zip(emotions[:5], scores[:5]):
                    emotion_name = str(e).lower().strip()
                    emoji = emotion_emoji.get(emotion_name, 'ğŸ˜Š')
                    st.info(f"{emoji} {str(e).capitalize()} ({score*100:.1f}%)")

st.markdown("---")

if analyze_button and user_text:
    cleaned_text = normalize_text(user_text)
    if len(cleaned_text.split()) >= 3:
        try:
            seq = tokenizer.texts_to_sequences([cleaned_text])
            # FIX: ThÃªm padding='post', truncating='post'
            padded = pad_sequences(seq, maxlen=100, padding='post', truncating='post')
            predictions = model.predict(padded, verbose=0)[0]
            
            st.subheader("ğŸ“Š CHI TIáº¾T Tá»ªNG NHÃƒN")
            
            # Táº¡o DataFrame - FIX: Bá» min_len trick
            emotion_names = label_map['label_name'].values
            scores = (predictions * 100).round(2)
            
            # Check khá»›p
            if len(emotion_names) != len(scores):
                st.error(f"âŒ Mismatch: {len(emotion_names)} labels â‰  {len(scores)} scores")
                st.stop()
            
            results_df = pd.DataFrame({
                "Cáº£m xÃºc": emotion_names,
                "XÃ¡c suáº¥t (%)": scores
            }).sort_values("XÃ¡c suáº¥t (%)", ascending=False)
            
            st.dataframe(results_df, use_container_width=True, height=400, hide_index=True)
            
            # Biá»ƒu Ä‘á»“
            try:
                chart_data = results_df.head(10).copy()
                chart_data = chart_data.set_index("Cáº£m xÃºc")
                st.bar_chart(chart_data)
            except Exception as chart_error:
                st.warning(f"âš ï¸ KhÃ´ng thá»ƒ hiá»ƒn thá»‹ biá»ƒu Ä‘á»“: {str(chart_error)}")
                
        except Exception as e:
            st.error(f"âŒ Lá»—i phÃ¢n tÃ­ch: {str(e)}")

st.markdown("ğŸ¤– Emotion Detection - CNN Model")
